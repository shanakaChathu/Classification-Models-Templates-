{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "color = sns.color_palette()\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as offline\n",
    "offline.init_notebook_mode()\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "import lightgbm as lgb\n",
    "\n",
    "import cufflinks as cf\n",
    "cf.go_offline()\n",
    "\n",
    "import xgboost as xgb \n",
    "from lightgbm import LGBMClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the tran and test dataframes \n",
    "application_train=\n",
    "application_test="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features dataframe using train and test set \n",
    "def featuresDF(df_train,df_test,target):\n",
    "    training=df_train\n",
    "    testing=df_test\n",
    "\n",
    "    training['is_train']=1\n",
    "    training['is_test']=0\n",
    "    testing['is_train']=0\n",
    "    testing['is_test']=1\n",
    "    \n",
    "    train_X=training.drop([target],axis=1)\n",
    "    test_X=testing\n",
    "    data=pd.concat([train_X,test_X],axis=0)\n",
    "    return data\n",
    "data=featuresDF(application_train,application_test,\"Comment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target variable extraction \n",
    "def target(df_train,target):\n",
    "    training=df_train\n",
    "    Y=training[target]\n",
    "    return Y\n",
    "    \n",
    "Y=target(application_train,'TARGET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Missing values Analysis \n",
    "def missingValuesAnalysis(data):\n",
    "    total = data.isnull().sum().sort_values(ascending = False)\n",
    "    percent = (data.isnull().sum()/data.isnull().count()*100).sort_values(ascending = False)\n",
    "    return pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "df=missingValuesAnalysis(application_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to capture numerical variables \n",
    "def _get_numerical_features(df):\n",
    "    feats=[col for col in list(df.columns) if df[col].dtype!='object']\n",
    "    return feats \n",
    "numFeatures=_get_numerical_features(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to capture categorical variables \n",
    "def _get_categorical_features(df):\n",
    "    feats=[col for col in list(df.columns) if df[col].dtype=='object']\n",
    "    return feats \n",
    "cats=_get_categorical_features(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to factorize categorical variables \n",
    "def _factorize_categoricals(df, cats):\n",
    "    for col in cats:\n",
    "        df[col], _ = pd.factorize(df[col])\n",
    "    return df \n",
    "#data=_factorize_categoricals(data,cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to convert categorical variables into dummy variables \n",
    "def _get_dummies(df,cats):\n",
    "    for col in cats:\n",
    "         df = pd.concat([df, pd.get_dummies(df[col], prefix=col)], axis=1)\n",
    "    return df\n",
    "#data=_get_dummies(data,cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doing factorize or dummy variable encoding \n",
    "def encoding(df,flag):\n",
    "    data_cats = _get_categorical_features(df)\n",
    "    if(flag==1):\n",
    "        df = _factorize_categoricals(df,data_cats)\n",
    "    else:\n",
    "        df=_get_dummies(df,data_cats)\n",
    "        df=df.drop(data_cats,axis=1)\n",
    "    return df\n",
    "data=encoding(data,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignoreFeatures = ['CUST_ID']\n",
    "importantFeatures = [col for col in data.columns if col not in ignoreFeatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting into train and test set \n",
    "ignoreFeatures = ['CUST_ID', 'is_train', 'is_test']\n",
    "importantFeatures = [col for col in data.columns if col not in ignoreFeatures]\n",
    "trainX = data[data['is_train'] == 1][importantFeatures]\n",
    "testX = data[data['is_test'] == 1][importantFeatures]\n",
    "x_train, x_val, y_train, y_val = train_test_split(trainX, Y, test_size=0.2, random_state=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 1 with train and test split - lgb.train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method1---Fitting LGB model with lgb.train \n",
    "lgb_train = lgb.Dataset(data=x_train, label=y_train)\n",
    "lgb_eval = lgb.Dataset(data=x_val, label=y_val)\n",
    "params = {'task': 'train', 'boosting_type': 'gbdt', 'objective': 'binary', 'metric': 'auc', 'max_bin':200,\n",
    "          'learning_rate': 0.01, 'num_leaves': 150, 'num_iteration':5000, 'verbose': 0 ,\n",
    "          'colsample_bytree':.9, 'subsample':.9, 'max_depth':30, 'reg_alpha':1, 'reg_lambda':1, \n",
    "          'min_split_gain':.01, 'min_child_weight':4}\n",
    "\n",
    "model = lgb.train(params,lgb_train,valid_sets=lgb_eval,early_stopping_rounds=150,verbose_eval=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction \n",
    "preds = model.predict(testX)\n",
    "test_id=application_test['CUST_ID']\n",
    "sub_lgb = pd.DataFrame()\n",
    "sub_lgb['CUST_ID'] = test_id\n",
    "sub_lgb['COMMENT'] = preds\n",
    "sub_lgb.to_csv(\"Prediction.csv\", index=False)\n",
    "sub_lgb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 2 with train and test split - lgbmclassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method2----Fitting LGB model with lgb classifier \n",
    "model = LGBMClassifier(boosting_type='gbdt', objective='multiclass',\n",
    "                       num_class=9,early_stopping = 50,num_iteration=10000,num_leaves=31,\n",
    "                       is_enable_sparse='true',tree_learner='data',min_data_in_leaf=600,max_depth=4,\n",
    "                       learning_rate=0.01, n_estimators=675, max_bin=255, subsample_for_bin=50000, \n",
    "                       min_split_gain=5, min_child_weight=5, min_child_samples=10, subsample=0.995, \n",
    "                       subsample_freq=1, colsample_bytree=1, reg_alpha=0, \n",
    "                       reg_lambda=0, seed=0, nthread=-1, silent=True)\n",
    "\n",
    "#Fit to training data\n",
    "eval_set = [(x_train, y_train), (x_val, y_val)]\n",
    "model=model.fit(x_train, y_train, eval_metric=[\"error\",\"auc\"], eval_set=eval_set, verbose=True)\n",
    "#Generate Predictions\n",
    "y_pred=model.predict_proba(test_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable importance \n",
    "lgb.plot_importance(model, figsize=(12, 25), max_num_features=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Method 3 with cross validation -No train test split --lgb.cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting LGB model using Cross validation(CV method) (lgb.cv)\n",
    "params = {'task': 'train', 'boosting_type': 'gbdt', 'objective': 'binary', 'metric': 'auc', 'max_bin':200,\n",
    "          'learning_rate': 0.01, 'num_leaves': 150, 'num_iteration':5000, 'verbose': 0 ,\n",
    "          'colsample_bytree':.8, 'subsample':.9, 'max_depth':9, 'reg_alpha':1, 'reg_lambda':1, \n",
    "          'min_split_gain':.01, 'min_child_weight':1}\n",
    "lgb_train = lgb.Dataset(data=trannX, label=Y)\n",
    "cvresult = lgb.cv(params, lgb_train, num_boost_round = 1000, nfold = 5, metrics = 'auc', early_stopping_rounds = 10, seed = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM model with tunning -gridserarch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "# using features, labels, cv_folds, model from previous example\n",
    "#model.set_params(n_estimators = 1600)\n",
    "param_test1 = {\n",
    "'max_depth': [6,7,8,9],\n",
    "'min_child_weight': [1,2,3,4],\n",
    "}\n",
    "features=trainX\n",
    "labels=Y\n",
    "gsearch1 = GridSearchCV(estimator = model, param_grid = param_test1, scoring = 'roc_auc', n_jobs = 4, iid = False,verbose = 2)\n",
    "gsearch1.fit(features,labels)\n",
    "#print gsearch1.grid_scores_\n",
    "print(gsearch1.best_params_)\n",
    "print(gsearch1.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
